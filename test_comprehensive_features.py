#!/usr/bin/env python3
"""
Comprehensive test script for all new features:
- Vector Clock implementation and causal ordering
- Delta Synchronization with chunk-based optimization
- Network topology visualization
- Performance metrics and monitoring
"""

import requests
import time
import json
import hashlib
from datetime import datetime

def calculate_file_hash(content):
    """Calculate SHA-256 hash of content."""
    if isinstance(content, str):
        content = content.encode('utf-8')
    return hashlib.sha256(content).hexdigest()

def test_comprehensive_features():
    """Test all comprehensive features."""
    print("üöÄ COMPREHENSIVE FEATURE TEST")
    print("=" * 60)
    
    base_url = "http://localhost:8000"
    timestamp = int(time.time())
    
    # Phase 1: Register multiple nodes
    print("\nüìù Phase 1: Node Registration & Vector Clock Initialization")
    nodes = []
    for i in range(4):
        node_id = f"feature_test_node_{i+1}_{timestamp}"
        node_data = {
            "node_id": node_id,
            "name": f"Feature Test Node {i+1}",
            "address": "localhost",
            "port": 8500 + i,
            "watch_directories": [f"/tmp/feature_test_{i+1}"],
            "capabilities": ["sync", "upload", "delta_sync"]
        }
        
        response = requests.post(f"{base_url}/api/register", json=node_data)
        if response.status_code == 200:
            result = response.json()
            nodes.append(node_id)
            print(f"   ‚úÖ {node_data['name']} registered with vector clock: {result.get('vector_clock', {})}")
        else:
            print(f"   ‚ùå Failed to register {node_data['name']}: {response.text}")
    
    if len(nodes) < 2:
        print("‚ùå Insufficient nodes registered for testing")
        return
    
    time.sleep(2)
    
    # Phase 2: Test Vector Clock System
    print("\n‚è∞ Phase 2: Vector Clock System Testing")
    
    # Get current vector clocks
    response = requests.get(f"{base_url}/api/vector-clocks")
    if response.status_code == 200:
        vector_clocks = response.json()
        print("   üìä Current Vector Clocks:")
        for node_id, clock_data in vector_clocks.items():
            print(f"      {node_id[:20]}...: {clock_data['display']} (max: {clock_data['max_time']})")
    
    # Phase 3: Delta Synchronization Testing
    print("\nüîÑ Phase 3: Delta Synchronization Testing")
    
    # Create initial file content
    base_content = "This is the initial file content for delta sync testing.\n" + "Line 2\n" * 50
    file_id = f"delta_test_file_{timestamp}"
    
    # Upload initial file
    print("   üì§ Uploading initial file...")
    upload_data = {
        "file_metadata": {
            "file_id": file_id,
            "name": "delta_test.txt",
            "path": f"/{nodes[0]}/delta_test.txt",
            "size": len(base_content),
            "hash": calculate_file_hash(base_content),
            "created_at": datetime.now().isoformat(),
            "modified_at": datetime.now().isoformat(),
            "owner_node": nodes[0],
            "version": 1,
            "vector_clock": {"clocks": {nodes[0]: 1}},
            "is_deleted": False,
            "content_type": "text/plain"
        },
        "chunks": [{
            "index": 0,
            "offset": 0,
            "size": len(base_content),
            "hash": calculate_file_hash(base_content),
            "data": base_content.encode().hex()
        }],
        "vector_clock": {"clocks": {nodes[0]: 1}},
        "use_delta_sync": False
    }
    
    response = requests.post(f"{base_url}/api/files/upload", json=upload_data)
    if response.status_code == 200:
        result = response.json()
        print(f"   ‚úÖ Initial file uploaded successfully")
        print(f"      Version ID: {result.get('version_id')}")
        print(f"      Sync Latency: {result.get('sync_latency', 0):.3f}s")
        if 'delta_metrics' in result:
            metrics = result['delta_metrics']
            print(f"      Delta Metrics: {metrics['chunks_total']} chunks, {metrics['bandwidth_saved']}B saved")
    else:
        print(f"   ‚ùå Initial file upload failed: {response.text}")
        return
    
    time.sleep(3)
    
    # Modify file content for delta sync
    print("   üîß Modifying file for delta sync test...")
    modified_content = base_content.replace("Line 2", "Modified Line 2")
    modified_content += "\nNew line added for delta sync test\n"
    
    # Upload modified file with delta sync
    upload_data_delta = {
        "file_metadata": {
            "file_id": file_id,
            "name": "delta_test.txt",
            "path": f"/{nodes[1]}/delta_test.txt",
            "size": len(modified_content),
            "hash": calculate_file_hash(modified_content),
            "created_at": datetime.now().isoformat(),
            "modified_at": datetime.now().isoformat(),
            "owner_node": nodes[1],
            "version": 2,
            "vector_clock": {"clocks": {nodes[1]: 1}},
            "is_deleted": False,
            "content_type": "text/plain"
        },
        "chunks": [{
            "index": 0,
            "offset": 0,
            "size": len(modified_content),
            "hash": calculate_file_hash(modified_content),
            "data": modified_content.encode().hex()
        }],
        "vector_clock": {"clocks": {nodes[1]: 1}},
        "use_delta_sync": True
    }
    
    response = requests.post(f"{base_url}/api/files/upload", json=upload_data_delta)
    if response.status_code == 200:
        result = response.json()
        print(f"   ‚úÖ Modified file uploaded with delta sync")
        if 'delta_metrics' in result:
            metrics = result['delta_metrics']
            print(f"      Compression Ratio: {metrics['compression_ratio']:.1f}%")
            print(f"      Bandwidth Saved: {metrics['bandwidth_saved']}B")
            print(f"      Chunks Reused: {metrics['chunks_unchanged']}/{metrics['chunks_total']}")
    else:
        print(f"   ‚ùå Delta sync upload failed: {response.text}")
    
    time.sleep(2)
    
    # Phase 4: Test Network Topology
    print("\nüåê Phase 4: Network Topology Testing")
    
    response = requests.get(f"{base_url}/api/network-topology")
    if response.status_code == 200:
        topology = response.json()
        print(f"   üìä Network Topology Retrieved:")
        print(f"      Coordinator: {topology['coordinator']['type']} at ({topology['coordinator']['x']}, {topology['coordinator']['y']})")
        print(f"      Nodes: {len(topology['nodes'])} active")
        print(f"      Connections: {len(topology['connections'])} total")
        
        for node in topology['nodes'][:3]:  # Show first 3 nodes
            print(f"         {node['name']}: {node['status']}, {node['file_count']} files, clock: {node['vector_clock']}")
    else:
        print(f"   ‚ùå Failed to get network topology: {response.text}")
    
    # Phase 5: Test Causal Ordering
    print("\nüîÄ Phase 5: Causal Ordering & Event Analysis")
    
    response = requests.get(f"{base_url}/api/causal-order?limit=10")
    if response.status_code == 200:
        events = response.json()
        print(f"   üìä Causal Order Analysis ({len(events)} events):")
        
        for i, event in enumerate(events[:5]):
            clock_str = json.dumps(event.get('vector_clock', {}).get('clocks', {}))
            print(f"      {i+1}. {event['event_type']} - Node: {event['node_id'][:12]}... - Clock: {clock_str}")
            if event.get('data', {}).get('file_name'):
                print(f"         File: {event['data']['file_name']} - Action: {event['data'].get('action', 'N/A')}")
    else:
        print(f"   ‚ùå Failed to get causal order: {response.text}")
    
    # Phase 6: Test Delta Metrics
    print("\nüìà Phase 6: Delta Synchronization Metrics")
    
    response = requests.get(f"{base_url}/api/delta-metrics")
    if response.status_code == 200:
        metrics = response.json()
        print(f"   üìä Delta Sync Performance:")
        print(f"      Total Bandwidth Saved: {metrics.get('total_bandwidth_saved', 0)}B")
        print(f"      Files Synchronized: {metrics.get('total_files_synced', 0)}")
        print(f"      Average Compression: {metrics.get('average_compression_ratio', 0):.1f}%")
        print(f"      Chunk Cache Size: {metrics.get('chunk_cache_size', 0)} chunks")
        print(f"      Chunk Size: {metrics.get('chunk_size', 4096)}B")
    else:
        print(f"   ‚ùå Failed to get delta metrics: {response.text}")
    
    # Phase 7: Conflict Detection Test
    print("\n‚ö†Ô∏è  Phase 7: Conflict Detection Testing")
    
    # Create concurrent modifications to test conflict detection
    if len(nodes) >= 3:
        print("   üîß Creating concurrent modifications...")
        
        # Node 2 modifies the file
        concurrent_content_1 = base_content.replace("initial file content", "MODIFIED BY NODE 2")
        upload_concurrent_1 = {
            "file_metadata": {
                "file_id": file_id,
                "name": "delta_test.txt",
                "path": f"/{nodes[2]}/delta_test.txt",
                "size": len(concurrent_content_1),
                "hash": calculate_file_hash(concurrent_content_1),
                "created_at": datetime.now().isoformat(),
                "modified_at": datetime.now().isoformat(),
                "owner_node": nodes[2],
                "version": 2,
                "vector_clock": {"clocks": {nodes[2]: 1}},  # Concurrent with node 1
                "is_deleted": False,
                "content_type": "text/plain"
            },
            "chunks": [{
                "index": 0,
                "offset": 0,
                "size": len(concurrent_content_1),
                "hash": calculate_file_hash(concurrent_content_1),
                "data": concurrent_content_1.encode().hex()
            }],
            "vector_clock": {"clocks": {nodes[2]: 1}},
            "use_delta_sync": True
        }
        
        response = requests.post(f"{base_url}/api/files/upload", json=upload_concurrent_1)
        if response.status_code == 200:
            print("   ‚úÖ Concurrent modification by Node 2 uploaded")
        
        time.sleep(1)
        
        # Check for conflicts
        response = requests.get(f"{base_url}/api/conflicts/detect/{file_id}")
        if response.status_code == 200:
            conflicts = response.json()
            if conflicts:
                print(f"   üö® Conflicts detected: {len(conflicts)}")
                for conflict in conflicts:
                    print(f"      Conflict between {conflict['nodes'][0][:12]}... and {conflict['nodes'][1][:12]}...")
            else:
                print("   ‚úÖ No conflicts detected (as expected for this test)")
        else:
            print(f"   ‚ùå Failed to check conflicts: {response.text}")
    
    # Phase 8: Performance Summary
    print("\nüìä Phase 8: Performance Summary")
    
    response = requests.get(f"{base_url}/api/metrics")
    if response.status_code == 200:
        final_metrics = response.json()
        print(f"   üéØ Final System Metrics:")
        print(f"      Total Sync Operations: {final_metrics.get('total_sync_operations', 0)}")
        print(f"      Total Bandwidth Saved: {final_metrics.get('total_bandwidth_saved', 0)}B")
        print(f"      Average Sync Latency: {final_metrics.get('average_sync_latency', 0):.3f}s")
        print(f"      Registered Nodes: {final_metrics.get('registered_nodes', 0)}")
        print(f"      Total Files: {final_metrics.get('total_files', 0)}")
        print(f"      Active Connections: {final_metrics.get('active_connections', 0)}")
    
    # Cleanup
    print("\nüßπ Cleanup Phase")
    for node_id in nodes:
        try:
            response = requests.delete(f"{base_url}/api/nodes/{node_id}")
            if response.status_code == 200:
                print(f"   ‚úÖ Removed {node_id[:20]}...")
            else:
                print(f"   ‚ö†Ô∏è  Failed to remove {node_id[:20]}...")
        except Exception as e:
            print(f"   ‚ùå Error removing {node_id[:20]}...: {e}")
    
    print("\n" + "=" * 60)
    print("üéâ COMPREHENSIVE FEATURE TEST COMPLETED!")
    print("üìã Features Tested:")
    print("   ‚úÖ Vector Clock Implementation & Causal Ordering")
    print("   ‚úÖ Delta Synchronization with Chunk Optimization")
    print("   ‚úÖ Network Topology Visualization Data")
    print("   ‚úÖ Performance Metrics & Monitoring")
    print("   ‚úÖ Conflict Detection System")
    print("   ‚úÖ Real-time Event Broadcasting")
    print("\nüåê Check the dashboard at http://localhost:3000 to see:")
    print("   ‚Ä¢ Network Topology tab for visual network representation")
    print("   ‚Ä¢ Vector Clocks tab for causal relationship analysis")
    print("   ‚Ä¢ Delta Sync tab for performance metrics and charts")
    print("   ‚Ä¢ Sync Monitor tab for real-time synchronization progress")

if __name__ == "__main__":
    test_comprehensive_features() 